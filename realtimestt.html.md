# TTS-parler


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
```

    : 
    [1;31mFailed to start the Kernel. 

    [1;31msniffio._impl.AsyncLibraryNotFoundError: unknown async library, or not in async context. 

    [1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details.

``` python
from RealtimeSTT import AudioToTextRecorder

# if __name__ == '__main__':
with AudioToTextRecorder() as recorder:
    print("Transcription: ", recorder.text())
```

    [2024-10-31 15:29:35.402] [ctranslate2] [thread 1195168] [warning] The compute type inferred from the saved model is float16, but the target device or backend do not support efficient float16 computation. The model weights have been automatically converted to use the float32 compute type instead.

    Transcription: eak now‚†π speak now‚†∏ speak now‚†º recording‚†¥ recording‚†¶ recording‚†ß recording‚†á recording‚†è recording‚†ã recording‚†ô recording‚†π recording‚†∏ recording‚†º recording‚†¥ recording‚†¶ recording transcribing‚†ô transcribing Vamos a practicar.
    RealtimeSTT shutting down
    Error in callback <function Halo.__init__.<locals>.clean_up> (for post_run_cell), with arguments args (<ExecutionResult object at 302a65880, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 302a65a90, raw_cell="from RealtimeSTT import AudioToTextRecorder

    # if .." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/matu/Xcode/Agents/nbs/04_tts.parler%20copy.ipynb#X20sZmlsZQ%3D%3D> result=None>,),kwargs {}:

    TypeError: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given
    [0;31m---------------------------------------------------------------------------[0m
    [0;31mTypeError[0m                                 Traceback (most recent call last)
    [0;31mTypeError[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given

    Error in callback <function Halo.__init__.<locals>.clean_up> (for post_run_cell), with arguments args (<ExecutionResult object at 302a65880, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 302a65a90, raw_cell="from RealtimeSTT import AudioToTextRecorder

    # if .." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/matu/Xcode/Agents/nbs/04_tts.parler%20copy.ipynb#X20sZmlsZQ%3D%3D> result=None>,),kwargs {}:

    TypeError: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given
    [0;31m---------------------------------------------------------------------------[0m
    [0;31mTypeError[0m                                 Traceback (most recent call last)
    [0;31mTypeError[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given

    Error in callback <function Halo.__init__.<locals>.clean_up> (for post_run_cell), with arguments args (<ExecutionResult object at 302a65880, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 302a65a90, raw_cell="from RealtimeSTT import AudioToTextRecorder

    # if .." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/matu/Xcode/Agents/nbs/04_tts.parler%20copy.ipynb#X20sZmlsZQ%3D%3D> result=None>,),kwargs {}:

    TypeError: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given
    [0;31m---------------------------------------------------------------------------[0m
    [0;31mTypeError[0m                                 Traceback (most recent call last)
    [0;31mTypeError[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given

    Error in callback <function Halo.__init__.<locals>.clean_up> (for post_run_cell), with arguments args (<ExecutionResult object at 302a65880, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 302a65a90, raw_cell="from RealtimeSTT import AudioToTextRecorder

    # if .." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/matu/Xcode/Agents/nbs/04_tts.parler%20copy.ipynb#X20sZmlsZQ%3D%3D> result=None>,),kwargs {}:

    TypeError: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given
    [0;31m---------------------------------------------------------------------------[0m
    [0;31mTypeError[0m                                 Traceback (most recent call last)
    [0;31mTypeError[0m: Halo.__init__.<locals>.clean_up() takes 0 positional arguments but 1 was given

``` python
device = "mps" if torch.backends.mps.is_available() else "cpu"
# device = "cuda:0" if torch.cuda.is_available() else "cpu"
device = "cpu"
```

``` python
model = ParlerTTSForConditionalGeneration.from_pretrained("parler-tts/parler-tts-mini-v1").to(device)
tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")
```

    /Users/matu/.local/share/virtualenvs/Agents-uluWm89Z/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
      WeightNorm.apply(module, name, dim)
    Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {
      "_name_or_path": "google/flan-t5-large",
      "architectures": [
        "T5ForConditionalGeneration"
      ],
      "classifier_dropout": 0.0,
      "d_ff": 2816,
      "d_kv": 64,
      "d_model": 1024,
      "decoder_start_token_id": 0,
      "dense_act_fn": "gelu_new",
      "dropout_rate": 0.1,
      "eos_token_id": 1,
      "feed_forward_proj": "gated-gelu",
      "initializer_factor": 1.0,
      "is_encoder_decoder": true,
      "is_gated_act": true,
      "layer_norm_epsilon": 1e-06,
      "model_type": "t5",
      "n_positions": 512,
      "num_decoder_layers": 24,
      "num_heads": 16,
      "num_layers": 24,
      "output_past": true,
      "pad_token_id": 0,
      "relative_attention_max_distance": 128,
      "relative_attention_num_buckets": 32,
      "tie_word_embeddings": false,
      "transformers_version": "4.46.1",
      "use_cache": true,
      "vocab_size": 32128
    }

    Config of the audio_encoder: <class 'parler_tts.dac_wrapper.modeling_dac.DACModel'> is overwritten by shared audio_encoder config: DACConfig {
      "_name_or_path": "parler-tts/dac_44khZ_8kbps",
      "architectures": [
        "DACModel"
      ],
      "codebook_size": 1024,
      "frame_rate": 86,
      "latent_dim": 1024,
      "model_bitrate": 8,
      "model_type": "dac_on_the_hub",
      "num_codebooks": 9,
      "sampling_rate": 44100,
      "torch_dtype": "float32",
      "transformers_version": "4.46.1"
    }

    Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {
      "_name_or_path": "/fsx/yoach/tmp/artefacts/parler-tts-mini/decoder",
      "activation_dropout": 0.0,
      "activation_function": "gelu",
      "add_cross_attention": true,
      "architectures": [
        "ParlerTTSForCausalLM"
      ],
      "attention_dropout": 0.0,
      "bos_token_id": 1025,
      "codebook_weights": null,
      "cross_attention_implementation_strategy": null,
      "dropout": 0.1,
      "eos_token_id": 1024,
      "ffn_dim": 4096,
      "hidden_size": 1024,
      "initializer_factor": 0.02,
      "is_decoder": true,
      "layerdrop": 0.0,
      "max_position_embeddings": 4096,
      "model_type": "parler_tts_decoder",
      "num_attention_heads": 16,
      "num_codebooks": 9,
      "num_cross_attention_key_value_heads": 16,
      "num_hidden_layers": 24,
      "num_key_value_heads": 16,
      "pad_token_id": 1024,
      "rope_embeddings": false,
      "rope_theta": 10000.0,
      "scale_embedding": false,
      "tie_word_embeddings": false,
      "torch_dtype": "float32",
      "transformers_version": "4.46.1",
      "use_cache": true,
      "use_fused_lm_heads": false,
      "vocab_size": 1088
    }

``` python
prompt = "Ola, tudo bem?"
description = "A brazilian customer service representative, female speaker. The voice is slightly expressive and animated, with a moderate speed and pitch. The recording is of very high quality and in portuguese, with the speaker's voice sounding clear and very close up."
```

``` python
input_ids = tokenizer(description, return_tensors="pt").input_ids.to(device)
prompt_input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)
```

``` python
generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)
audio_arr = generation.cpu().numpy().squeeze()
```

``` python
sf.write("parler_tts_out.wav", audio_arr, model.config.sampling_rate)
```
