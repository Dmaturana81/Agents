{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval:false\n",
    "\n",
    "class Connection(OpenAISchema):\n",
    "    \"\"\"Class that manage the connection to the database, Some base methods to bring description information, and other to execute queries\"\"\"\n",
    "\n",
    "    sql_warehouse_id: str \n",
    "    instance: str \n",
    "    uri_sql_endpoint: str | None = None\n",
    "    uri_sql_history: str | None = None\n",
    "    catalog: str\n",
    "    database: str\n",
    "    token: str\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    @classmethod\n",
    "    def connect(cls, values):\n",
    "        values['uri_sql_endpoint'] = \"https://{instance}/api/2.0/sql/statements/\".format(instance=values['instance'])\n",
    "        values['uri_sql_history'] = \"https://{instance}/api/2.0/sql/history/queries\".format(instance=values['instance'])\n",
    "        return values\n",
    "\n",
    "    def generate_headers(self) -> Dict[str, str]:\n",
    "        \"\"\"Method to generate the headers for the connection\"\"\"\n",
    "        return {\n",
    "            \"Authorization\": f\"Bearer {self.token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "    def generate_data_post(\n",
    "        self,\n",
    "        query_to_execute: str,\n",
    "        fmt: Literal[\"CSV\", \"ARROW_STREAM\", \"JSON_ARRAY\"] = \"JSON_ARRAY\",\n",
    "        disposition: Literal[\"INLINE\", \"diff\"] = \"INLINE\",\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"Method that generate the body of the post request to execute the query in the SQL Warehouse\"\"\"\n",
    "        data = {\n",
    "            \"warehouse_id\": f\"{self.sql_warehouse_id}\",\n",
    "            \"format\": fmt,  # for big use CSV, ARROW_STREAM, JSON_ARRAY is default for small <25mb\n",
    "            \"disposition\": disposition,  # for big security attention with token here, needs to be diff, INLINE is default\n",
    "            \"statement\": query_to_execute, # query to execute\n",
    "            \"catalog\": f\"{self.catalog}.{self.database}\", # catalog and database to use\n",
    "            \"wait_timeout\": \"0s\",\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def parse_result(cls, data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Class method to parse the result into a dataframe compatible format\n",
    "        Args:\n",
    "            data (Dict): data from the SQL Warehouse\n",
    "        Returns:\n",
    "            Dict: dictionary with columns and data\n",
    "        \"\"\"\n",
    "        columns = [x[\"name\"] for x in data[\"manifest\"][\"schema\"][\"columns\"]]\n",
    "        results = data[\"result\"][\"data_array\"]\n",
    "        return {\"columns\": columns, \"data\": results}\n",
    "\n",
    "#| exports\n",
    "@patch\n",
    "def get_tables(\n",
    "            self:'Connection'\n",
    "        ) -> List[str]:\n",
    "    \"\"\"Method to list tables available in the database\n",
    "    Returns:\n",
    "        List[str]: list of tables names\n",
    "    \"\"\"\n",
    "    query = f\"SHOW TABLES in {self.catalog}.{self.database}\"\n",
    "    data = self.execute_query(query)\n",
    "    tables = data[\"data\"]  # self.parse_result(data)['data']\n",
    "    return [f\"{self.catalog}.{x[0]}.{x[1]}\" for x in tables if x[1].find(\"payload\") == -1]\n",
    "#| export\n",
    "@patch\n",
    "def get_table_columns(\n",
    "        self:'Connection',\n",
    "        table: str\n",
    "    ) -> List[str]:\n",
    "    \"\"\"Method to get the columns of a table\n",
    "    Args:\n",
    "        table (str): table name\n",
    "    Returns:\n",
    "        List[str]: list of columns\n",
    "    \"\"\"\n",
    "    query = f\"DESCRIBE TABLE {table}\"\n",
    "    data = self.execute_query(query)\n",
    "    return [x[0] for x in data[\"data\"]]  # self.parse_result(data)['data']]\n",
    "\n",
    "\n",
    "#| export\n",
    "@patch\n",
    "def get_tables_columns(\n",
    "        self:'Connection', \n",
    "    ) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Method to get the tables and columns\n",
    "    Returns:\n",
    "        Dict[str, List[str]]: dictionary with table name as key and list of columns\n",
    "    \"\"\"\n",
    "    tables = self.get_tables()\n",
    "    tables_columns = {}\n",
    "    for table in tables:\n",
    "        table_columns = self.get_table_columns(table)\n",
    "        tables_columns[table] = table_columns\n",
    "    return tables_columns\n",
    "    \n",
    "\n",
    "#| export\n",
    "@classmethod\n",
    "@patch\n",
    "def row_2_str(\n",
    "        cls:'Connection',\n",
    "        row\n",
    "    ):\n",
    "    \"\"\"Method to convert a column from the table description into a string, spcifying the name, type and comment availables\n",
    "    Args:\n",
    "        row: row to convert\n",
    "    Returns:\n",
    "        str: row as string\n",
    "    \"\"\"\n",
    "    return f\"{row[0]} ( {row[1] if row[1] else ''} {row[2] if row[2] else ''})\"\n",
    "\n",
    "#| export\n",
    "@classmethod\n",
    "@patch\n",
    "def list_cols(\n",
    "        cls:'Connection',\n",
    "        df\n",
    "    ):\n",
    "    \"\"\"Method to list the columns of a table\n",
    "    Args:\n",
    "        df: dataframe with the columns\n",
    "    Returns:\n",
    "        List[str]: list of columns as string\n",
    "    \"\"\"\n",
    "    end_i = df.loc[df['col_name'] == ''].index[0]\n",
    "    cols = df.loc[:end_i-1] #usar i -1\n",
    "    return cols.apply(lambda row: cls.row_2_str(row), axis=1).to_list()\n",
    "\n",
    "\n",
    "#| export\n",
    "@patch\n",
    "def get_table_description(\n",
    "        self:'Connection', \n",
    "        table: str\n",
    "    ) -> Dict[str, str]:\n",
    "    \"\"\"Method that returns the table description from Databricks\n",
    "    Args:\n",
    "        table (str): table name\n",
    "    Returns:\n",
    "        Dict[str, str]: dictionary with table and description\n",
    "    \"\"\"\n",
    "    query = f\"DESCRIBE TABLE EXTENDED {table}\"\n",
    "    data = self.execute_query(query)\n",
    "    df = pd.DataFrame(data['data'], columns = data['columns'])\n",
    "    cols = self.list_cols(df)\n",
    "    comment =  df.loc[df['col_name'] == 'Comment']['data_type'].values[0]\n",
    "    return {\"table\": table, \"description\": comment, \"columns\":cols}  # data #self.parse_result(data)\n",
    "\n",
    "#| export\n",
    "@patch\n",
    "def get_tables_descriptions(\n",
    "        self:'Connection',\n",
    "        tables: list[str] | None = None\n",
    "    ) -> List[Dict[str, str]]:\n",
    "    \"\"\"Function that return the tables and the description\n",
    "    Args:\n",
    "        tables (list[str], optional): list of tables. Defaults to None.\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: list of dictionaries with table and description\n",
    "    \"\"\"\n",
    "    tables = tables if tables else self.get_tables()\n",
    "    tables_description = []\n",
    "    for table in tables:\n",
    "        table_desc = self.get_table_description(table)\n",
    "        tables_description.append(table_desc)\n",
    "    return tables_description\n",
    "\n",
    "#| export\n",
    "@patch\n",
    "def execute_query(\n",
    "        self:'Connection', \n",
    "        query: str\n",
    "    ):\n",
    "    \"\"\"Method that execute the query in the SQL Warehouse\n",
    "    Args:\n",
    "        query (str): query to execute\n",
    "    Returns:\n",
    "        Dict: dictionary with the result of the query\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        self.uri_sql_endpoint,\n",
    "        headers=self.generate_headers(),\n",
    "        data=json.dumps(self.generate_data_post(query)),\n",
    "    )\n",
    "    data = response.json()\n",
    "    while data[\"status\"][\"state\"] != \"SUCCEEDED\":\n",
    "        status = data[\"status\"][\"state\"] \n",
    "        match status:\n",
    "            case \"RUNNING\":\n",
    "                time.sleep(0.5)\n",
    "                response = requests.get(\n",
    "                    self.uri_sql_endpoint + data[\"statement_id\"],\n",
    "                    headers=self.generate_headers(),\n",
    "                )\n",
    "                data = response.json()\n",
    "            case \"PENDING\":\n",
    "                time.sleep(0.5)\n",
    "                response = requests.get(\n",
    "                    self.uri_sql_endpoint + data[\"statement_id\"],\n",
    "                    headers=self.generate_headers(),\n",
    "                )\n",
    "                data = response.json()\n",
    "            case \"FAILED\":\n",
    "                raise Exception(traceback.format_exc()) # raise the exception and return the traceback as details, this will be use to cirrect the query made by the LLM\n",
    "    return self.parse_result(data)\n",
    "def create_con():\n",
    "        return Connection(token=os.getenv('DATABRICKS_TOKEN'), catalog = \"text2sql\", database = \"default\", instance = os.getenv('SQL_INSTANCE'), sql_warehouse_id = os.getenv('SQL_WAREHOUSE_ID'))\n",
    "con = create_con()\n",
    "con.get_tables()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
